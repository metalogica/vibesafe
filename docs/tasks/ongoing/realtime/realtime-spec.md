# Realtime Streaming Analysis: Technical Specification

**Version**: 1.0.0
**Status**: Draft
**Author**: Architect Agent
**Date**: 2026-02-21

---

## 1. Overview

### Objective

Eliminate perceived latency during the security analysis phase by streaming Claude's response incrementally to the UI. Currently, the user pastes a URL and waits with no visual feedback while the Claude API call completes (~30-60s), then all vulnerabilities appear at once. After this change, the user will see:

1. Raw analysis text streaming into the AgentFeed as Claude generates it
2. Vulnerability cards appearing one-by-one in the VulnerabilitiesPanel as they're parsed from the stream
3. Full prompt/response pairs persisted in the DB for debugging and transparency

### Constraints

- MUST NOT break existing audit lifecycle state machine (`pending → fetching → analyzing → evaluating → complete | failed`)
- MUST NOT change the Claude prompt format or expected JSON response structure
- MUST stay within Convex action wall-clock budget (540s)
- MUST throttle streaming text DB updates to avoid excessive Convex mutations (~1 update per second)
- MUST maintain all existing FMEA mitigations (action budget, sanitization, error normalization)

### Success Criteria

- User sees streaming text appear in AgentFeed within 2s of the analysis phase starting
- Each vulnerability card appears in VulnerabilitiesPanel within 1s of being fully generated by Claude (not batched at the end)
- Full inference data (prompt + response) is queryable in the `audit_inferences` table after completion
- All existing unit tests continue to pass

---

## 2. Scope

| In Scope | Out of Scope |
|----------|--------------|
| Streaming Anthropic API integration | Multi-agent conversations (future brief) |
| Incremental vulnerability parsing during stream | Changes to Claude prompt or response format |
| New `audit_inferences` table for raw inference storage | Authentication / authorization |
| Streaming text display in AgentFeed | Streaming for ingestion phase (GitHub fetching) |
| Frontend subscription to live inference text | Token-by-token rendering (we batch ~1s updates) |
| Convex CRUD functions for inferences | Retry logic for failed streams |

---

## 3. Data Model

### 3.1 New Table: `audit_inferences`

```typescript
// In convex/schema.ts — add to existing defineSchema({...})

audit_inferences: defineTable({
  auditId: v.id('audits'),
  agent: v.string(),                    // 'SECURITY_ANALYST' (extensible for future agents)
  model: v.string(),                    // 'claude-sonnet-4-5-20250929'
  prompt: v.string(),                   // Full prompt sent to Claude
  response: v.optional(v.string()),     // Complete response text (set on completion)
  streamingText: v.string(),            // Accumulated text (updated during streaming)
  status: v.union(
    v.literal('streaming'),
    v.literal('complete'),
    v.literal('failed'),
  ),
  inputTokens: v.optional(v.number()),  // From usage.input_tokens
  outputTokens: v.optional(v.number()), // From usage.output_tokens
  error: v.optional(v.string()),        // Error message if failed
}).index('by_audit', ['auditId']),
```

**Field semantics:**

| Field | When Set | By Whom |
|-------|----------|---------|
| `prompt` | At creation (before streaming starts) | `startAuditAction` |
| `streamingText` | Initialized to `''`, updated every ~1s during streaming | `startAuditAction` via throttled mutation |
| `response` | Once when stream completes | `startAuditAction` |
| `status` | `'streaming'` at creation → `'complete'` or `'failed'` | `startAuditAction` |
| `inputTokens`, `outputTokens` | Once when stream completes (from `message_stop` event) | `startAuditAction` |

### 3.2 Existing Tables (No Changes)

The following tables are unchanged:
- `audits` — status lifecycle unchanged
- `audit_analyses` — vulnerability records (now inserted incrementally during streaming instead of after)
- `audit_evaluations` — unchanged
- `audit_events` — unchanged (vulnerability events still created per-vuln)

---

## 4. Streaming Claude Client

### 4.1 Architecture

Replace the current blocking `runSecurityAnalysis()` with a streaming variant that accepts an action context and callbacks:

```
┌─────────────────────────────────────────────┐
│           startAuditAction                   │
│                                              │
│  1. Create audit_inferences (streaming)      │
│  2. Call runStreamingAnalysis(ctx, files, {   │
│       onTextDelta → throttled DB update      │
│       onVulnerability → insert analysis+event│
│       onComplete → finalize inference record │
│     })                                       │
│  3. Continue to evaluation phase             │
└─────────────────────────────────────────────┘
```

### 4.2 Streaming Function Signature

```typescript
// convex/clients/claude.ts — new export

interface StreamingCallbacks {
  onTextDelta: (accumulatedText: string) => Promise<void>;
  onVulnerabilityParsed: (vuln: Vulnerability, seqNumber: number) => Promise<void>;
  onComplete: (result: {
    fullResponse: string;
    inputTokens: number;
    outputTokens: number;
  }) => Promise<void>;
  onError: (error: { code: string; message: string }) => Promise<void>;
}

export async function runStreamingSecurityAnalysis(
  files: { path: string; content: string }[],
  callbacks: StreamingCallbacks,
): Promise<ClaudeClientResult<{ vulnerabilities: Vulnerability[] }>>
```

### 4.3 SSE Parsing

The Anthropic streaming API returns Server-Sent Events. Key event types to handle:

| Event Type | Action |
|------------|--------|
| `content_block_delta` with `delta.type === 'text_delta'` | Accumulate `delta.text`, feed to incremental parser, throttle `onTextDelta` |
| `message_delta` with `usage` | Extract `output_tokens` |
| `message_start` with `message.usage` | Extract `input_tokens` |
| `message_stop` | Call `onComplete` with full response and token counts |
| `error` | Call `onError` |

SSE line parsing rules:
- Lines starting with `event: ` set the event type
- Lines starting with `data: ` contain JSON payload
- Empty lines delimit events
- Lines starting with `data: [DONE]` signal stream end (Anthropic doesn't use this — uses `message_stop` event instead)

### 4.4 Throttling Strategy

The `onTextDelta` callback triggers a Convex mutation to update `streamingText`. To avoid excessive DB writes:

- **Minimum interval**: 1000ms between updates
- **Minimum delta**: 200 characters since last flush
- **Always flush**: On `onComplete` (final text) and on each `onVulnerabilityParsed`
- **Implementation**: Track `lastFlushTime` and `lastFlushLength` in the streaming loop

### 4.5 Backward Compatibility

The existing `runSecurityAnalysis` function is **kept** (not deleted). The streaming variant is a new export. This ensures tests and any future non-streaming use cases still work.

---

## 5. Incremental Vulnerability Parser

### 5.1 Location

`src/domain/audit/incrementalVulnerabilityParser.ts` — pure function, no Convex dependency.

### 5.2 Design

The Claude response JSON has this structure:
```json
{
  "vulnerabilities": [
    { "category": "...", "level": "...", ... },
    { "category": "...", "level": "...", ... }
  ]
}
```

The parser uses a state machine with brace-depth tracking to detect complete vulnerability objects within the `vulnerabilities` array as text streams in.

### 5.3 Interface

```typescript
export interface IncrementalVulnerabilityParser {
  /**
   * Feed a chunk of text from the stream.
   * Returns an array of newly-completed, Zod-validated vulnerability objects.
   * Returns empty array if no new complete objects were found.
   */
  feed(chunk: string): Vulnerability[];

  /**
   * Get count of vulnerabilities parsed so far.
   * Useful for calculating seqNumber.
   */
  getParsedCount(): number;
}

export function createIncrementalVulnerabilityParser(): IncrementalVulnerabilityParser;
```

### 5.4 State Machine

```
SCANNING → found '"vulnerabilities"' → FOUND_KEY
FOUND_KEY → found '[' → IN_ARRAY
IN_ARRAY → found '{' (depth 0→1) → IN_OBJECT
IN_OBJECT → found '}' (depth 1→0) → extract object text → validate → emit → IN_ARRAY
IN_ARRAY → found ']' → DONE
```

**Rules:**
- Track brace depth only within the vulnerabilities array (ignore outer `{` / `}`)
- Handle escaped characters inside strings (e.g., `\"`, `\\`)
- Handle string literals (don't count braces inside strings)
- On each complete `{...}` at depth 0 within the array, attempt `JSON.parse` + `VulnerabilitySchema.safeParse`
- Skip malformed objects (log warning, don't throw) — continue parsing the next object
- The parser is stateful (call `feed()` repeatedly with successive chunks)

### 5.5 Edge Cases

| Case | Behavior |
|------|----------|
| Claude wraps JSON in markdown code fences | Parser scans past ` ```json ` prefix before entering SCANNING state |
| A vulnerability object spans multiple chunks | State persists across `feed()` calls; object is only emitted when the closing `}` arrives |
| Malformed object (invalid JSON or Zod failure) | Skip it, return empty for that object, continue to next |
| No vulnerabilities array in response | Returns empty array for every `feed()` call; final JSON parse (after stream) will catch the error |
| Nested objects inside vulnerability fields | Brace depth tracks correctly; only depth 0→1→0 transitions emit |

---

## 6. Pipeline Integration

### 6.1 Changes to `convex/services/startAuditAction.ts`

The ANALYSIS PHASE section (lines 157-202) is refactored:

**Before** (current):
```
1. Call runSecurityAnalysis(files)  ← blocking, waits for full response
2. sanitizeVulnerabilities(result)
3. Loop: insert each vulnerability + event
```

**After** (streaming):
```
1. Build prompt text
2. Insert audit_inferences record (status: 'streaming', prompt: promptText)
3. Call runStreamingSecurityAnalysis(files, {
     onTextDelta: update audit_inferences.streamingText (throttled)
     onVulnerabilityParsed: sanitize + insert audit_analyses + audit_events
     onComplete: update audit_inferences (response, tokens, status: 'complete')
     onError: update audit_inferences (status: 'failed', error)
   })
4. If streaming returned error, fail the audit
5. Continue to EVALUATION PHASE (unchanged)
```

### 6.2 Callback Implementations

Each callback is implemented inline in `startAuditAction.ts`, calling Convex mutations:

```typescript
// onTextDelta — throttled
onTextDelta: async (accumulatedText) => {
  await ctx.runMutation(internal.inferences.updateStreamingText, {
    inferenceId,
    streamingText: accumulatedText,
  });
}

// onVulnerabilityParsed — immediate
onVulnerabilityParsed: async (vuln, seqNumber) => {
  const sanitized = sanitizeVulnerabilities([vuln as Record<string, unknown>]);
  if (sanitized.length === 0) return;

  const v = sanitized[0];
  const displayId = generateDisplayId(auditId, seqNumber);

  const analysisId = await ctx.runMutation(internal.analyses.create, {
    auditId, seqNumber, displayId,
    category: v.category, level: v.level, title: v.title,
    description: v.description, impact: v.impact,
    filePath: v.filePath, fix: v.fix,
  });

  await ctx.runMutation(internal.auditEvents.create, {
    auditId, agent: 'SECURITY_ANALYST',
    message: generateAnalystMessage(v, displayId),
    analysisId,
  });
}

// onComplete — finalize
onComplete: async ({ fullResponse, inputTokens, outputTokens }) => {
  await ctx.runMutation(internal.inferences.complete, {
    inferenceId,
    response: fullResponse,
    inputTokens,
    outputTokens,
  });
}
```

### 6.3 Evaluation Phase

No changes. After the streaming analysis completes, the evaluation phase runs exactly as before. The vulnerabilities are already in `audit_analyses` (inserted incrementally), so `calculateSafetyProbability` and `generateExecutiveSummary` work unchanged.

The only difference: vulnerabilities may have been sanitized individually during streaming rather than as a batch. The `sanitizeVulnerabilities` function handles single-element arrays correctly.

---

## 7. Convex Functions for Inferences

### 7.1 File: `convex/inferences.ts`

```typescript
// Query: get active streaming inference for an audit
export const getStreamingByAudit = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    const inferences = await ctx.db
      .query('audit_inferences')
      .withIndex('by_audit', (q) => q.eq('auditId', auditId))
      .collect();
    // Return the most recent streaming inference, or null
    return inferences.find((i) => i.status === 'streaming') ?? null;
  },
});

// Query: list all inferences for an audit (for transparency/debugging)
export const listByAudit = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    return await ctx.db
      .query('audit_inferences')
      .withIndex('by_audit', (q) => q.eq('auditId', auditId))
      .collect();
  },
});

// Internal mutation: create inference record
export const create = internalMutation({
  args: {
    auditId: v.id('audits'),
    agent: v.string(),
    model: v.string(),
    prompt: v.string(),
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert('audit_inferences', {
      ...args,
      streamingText: '',
      status: 'streaming',
    });
  },
});

// Internal mutation: update streaming text
export const updateStreamingText = internalMutation({
  args: {
    inferenceId: v.id('audit_inferences'),
    streamingText: v.string(),
  },
  handler: async (ctx, { inferenceId, streamingText }) => {
    await ctx.db.patch(inferenceId, { streamingText });
  },
});

// Internal mutation: mark complete
export const complete = internalMutation({
  args: {
    inferenceId: v.id('audit_inferences'),
    response: v.string(),
    inputTokens: v.number(),
    outputTokens: v.number(),
  },
  handler: async (ctx, { inferenceId, response, inputTokens, outputTokens }) => {
    await ctx.db.patch(inferenceId, {
      response,
      inputTokens,
      outputTokens,
      status: 'complete',
      streamingText: response, // Final text = complete response
    });
  },
});

// Internal mutation: mark failed
export const fail = internalMutation({
  args: {
    inferenceId: v.id('audit_inferences'),
    error: v.string(),
  },
  handler: async (ctx, { inferenceId, error }) => {
    await ctx.db.patch(inferenceId, { status: 'failed', error });
  },
});
```

---

## 8. Frontend Changes

### 8.1 SecurityAuditApp — New Subscription

Add a `useQuery` subscription for the active streaming inference:

```typescript
// In SecurityAuditApp.tsx, alongside existing subscriptions:
const streamingInference = useQuery(
  api.inferences.getStreamingByAudit,
  currentAuditId ? { auditId: currentAuditId } : 'skip',
);
```

Pass the streaming text to AgentFeed:

```typescript
<AgentFeed
  messages={messages}
  isAuditing={uiStatus === 'auditing' && !selectedCommitHash}
  streamingText={streamingInference?.streamingText ?? null}
/>
```

### 8.2 AgentFeed — Streaming Text Display

Update `AgentFeedProps` to accept optional streaming text:

```typescript
interface AgentFeedProps {
  messages: AgentMessage[];
  isAuditing: boolean;
  streamingText: string | null;  // NEW
}
```

Render a streaming text block after all messages, when `streamingText` is non-null and non-empty:

```tsx
{/* After the messages map, before the empty state */}
{streamingText && (
  <motion.div
    key="streaming"
    initial={{ opacity: 0 }}
    animate={{ opacity: 1 }}
    className="flex gap-4 border-b border-[#1C2430]/50 p-4 bg-emerald-500/5"
  >
    <div className="shrink-0 pt-1">
      <div className="flex h-8 w-8 items-center justify-center rounded-lg border bg-emerald-500/10 border-emerald-500/30 text-emerald-400">
        <ShieldAlert className="h-4 w-4" />
      </div>
    </div>
    <div className="min-w-0 flex-1">
      <div className="mb-1 flex items-center gap-2">
        <span className="text-xs font-bold uppercase tracking-wider text-emerald-400">
          Security Analyst
        </span>
        <span className="text-[10px] text-emerald-400/60 animate-pulse">
          analyzing...
        </span>
      </div>
      <pre className="text-xs font-light leading-relaxed text-[#E6EEF8]/70 whitespace-pre-wrap font-sans max-h-48 overflow-y-auto">
        {streamingText}
      </pre>
    </div>
  </motion.div>
)}
```

**Auto-scroll**: The existing `useEffect` on `messages` must also trigger on `streamingText`:

```typescript
useEffect(() => {
  if (scrollRef.current) {
    scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
  }
}, [messages, streamingText]);
```

### 8.3 No Changes Required

- **VulnerabilitiesPanel**: Already reactively subscribes to `analyses` via `useQuery`. Vulnerability cards will appear automatically as `audit_analyses` records are inserted during streaming.
- **DeploymentSafetyChart**: Already computes `currentConsensus` from `analyses` via `useMemo`. Score updates as vulnerabilities stream in.
- **VulnerabilityModal**: No changes.
- **auditMappers.ts**: No changes.
- **types.ts**: No changes.

---

## 9. Error Handling & FMEA

### 9.1 Failure Modes

| # | Failure Mode | Severity | Mitigation |
|---|-------------|----------|------------|
| 1 | Stream drops midway (network error) | High | `onError` callback marks inference as failed. Existing try/catch in `startAuditAction` marks audit as failed. Partial vulnerabilities already inserted remain visible. |
| 2 | Claude returns non-JSON in stream | Medium | Incremental parser stays in SCANNING state, emits no vulnerabilities. After stream completes, `runStreamingSecurityAnalysis` detects no vulns parsed and returns `INVALID_RESPONSE` error. |
| 3 | Individual vulnerability object malformed | Low | Parser skips it (Zod validation failure on individual object). Other vulnerabilities still parse. Warning logged. |
| 4 | Excessive streaming mutations overload Convex | Medium | Throttling: max 1 `updateStreamingText` mutation per second. At most ~60 updates per minute-long analysis. |
| 5 | Action budget exceeded during streaming | High | Existing `isOverBudget()` check before analysis phase. If stream takes too long, Convex action timeout (10 min) triggers error. Try/catch envelope marks audit as failed. |
| 6 | Streaming text becomes very large | Low | Claude's `max_tokens: 8192` caps output to ~32KB of text. `streamingText` field stores at most this amount. |

### 9.2 Recovery

- **Partial vulnerabilities**: If the stream fails partway, vulnerabilities already inserted are valid and useful. The audit is marked `failed`, but the partial results are preserved.
- **Inference record**: Always reaches terminal state (`complete` or `failed`) via the try/catch envelope.
- **Idempotency**: Each audit creates a fresh inference record. Re-running the audit creates a new audit + new inference.

---

## 10. Testing Strategy

### 10.1 Unit Tests

| Test | File | What It Verifies |
|------|------|-----------------|
| Incremental parser — single chunk | `test/unit/domain/audit/incrementalVulnerabilityParser.test.ts` | Parses all vulnerabilities from a complete JSON string in one `feed()` call |
| Incremental parser — multi chunk | Same | Splits JSON across multiple `feed()` calls, verifies correct vulnerabilities are emitted at the right time |
| Incremental parser — code fence handling | Same | Handles `\`\`\`json` prefix before the JSON object |
| Incremental parser — malformed object | Same | Skips invalid vulnerability, continues parsing remaining objects |
| Incremental parser — string escaping | Same | Braces inside string values (e.g., `"description": "use { and }"`) don't break depth tracking |
| Incremental parser — nested objects | Same | Handles potential nested objects in vulnerability fields |
| SSE event parsing | `test/unit/server/sseParser.test.ts` | Correctly extracts text deltas from Anthropic SSE format |

### 10.2 Integration Tests

| Test | What It Verifies |
|------|-----------------|
| Streaming client with mocked fetch | Returns streaming ReadableStream, callbacks fire in correct order |
| Pipeline with mocked streaming client | Inference record created → streaming text updated → vulnerabilities inserted incrementally → inference completed |

### 10.3 Manual Verification

- Start an audit on a real repo
- Observe: streaming text appears in AgentFeed within 2s of analysis starting
- Observe: vulnerability cards pop into VulnerabilitiesPanel one-by-one
- Observe: safety score updates as each vulnerability appears
- Verify: `audit_inferences` record contains full prompt and response after completion

---

## 11. Key Design Decision: Incremental Parsing vs. Tool Use

> **Insight**: Brace-depth parsing of the existing JSON format is simpler and lower-risk than changing the Claude integration to use tool calls.

**Why this matters:**

| Approach | Behavior | Trade-off |
|----------|----------|-----------|
| Tool use (`report_vulnerability` tool) | Claude calls a tool for each finding. Cleaner per-vuln boundaries. | Requires changing the Claude prompt, adding tool definitions, and handling tool-use streaming events. Higher risk of affecting analysis quality. |
| **Brace-depth incremental parser** | Parse the existing JSON format as it streams. No prompt changes. | Requires a stateful parser with string-escape handling. But it's a pure function, easily unit-tested, and zero risk to analysis quality. |

The incremental parser approach preserves the exact same Claude prompt and JSON format, isolating the streaming change to the transport layer only. This aligns with the constraint of not changing the prompt.

---

## 12. Prompt Execution Strategy

### Phase 1: Schema & Inference CRUD

> Gate: `pnpm app:compile`

#### Step 1.1: Add `audit_inferences` Table to Schema

Read `convex/schema.ts`. Add the `audit_inferences` table definition as specified in Section 3.1 of this spec. Place it after the `audit_events` table definition.

The table has these fields:
- `auditId: v.id('audits')`
- `agent: v.string()`
- `model: v.string()`
- `prompt: v.string()`
- `response: v.optional(v.string())`
- `streamingText: v.string()`
- `status: v.union(v.literal('streaming'), v.literal('complete'), v.literal('failed'))`
- `inputTokens: v.optional(v.number())`
- `outputTokens: v.optional(v.number())`
- `error: v.optional(v.string())`

Add index: `.index('by_audit', ['auditId'])`

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 1.2: Create Inference CRUD Functions

Create file `convex/inferences.ts` with the following functions as specified in Section 7.1 of this spec:

**Public queries:**
- `getStreamingByAudit(auditId)` — returns the most recent inference with `status === 'streaming'`, or null
- `listByAudit(auditId)` — returns all inferences for an audit

**Internal mutations:**
- `create({ auditId, agent, model, prompt })` — inserts with `streamingText: ''` and `status: 'streaming'`
- `updateStreamingText({ inferenceId, streamingText })` — patches streamingText
- `complete({ inferenceId, response, inputTokens, outputTokens })` — patches response, tokens, sets `status: 'complete'` and `streamingText: response`
- `fail({ inferenceId, error })` — patches error, sets `status: 'failed'`

Import patterns:
- `import { v } from 'convex/values';`
- `import { query, internalMutation } from './_generated/server';`

Follow existing patterns in `convex/auditEvents.ts` and `convex/analyses.ts` for style reference.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Gate
- `pnpm app:compile`

---

### Phase 2: Incremental Vulnerability Parser

> Gate: `pnpm app:compile && pnpm vitest run test/unit/domain/audit/incrementalVulnerabilityParser.test.ts --config vitest.config.unit.ts`

#### Step 2.1: Create Incremental Parser

Create file `src/domain/audit/incrementalVulnerabilityParser.ts`.

This is a pure function module with no Convex dependency. Import `VulnerabilitySchema` from `../../convex/services/schemas` for validation.

Implement `createIncrementalVulnerabilityParser()` as specified in Section 5 of this spec. The parser:

1. Exports an `IncrementalVulnerabilityParser` interface with `feed(chunk: string): Vulnerability[]` and `getParsedCount(): number`
2. Uses a state machine: `SCANNING → FOUND_KEY → IN_ARRAY → IN_OBJECT → (emit) → IN_ARRAY → DONE`
3. Tracks brace depth within the vulnerabilities array
4. Handles string literals (don't count braces inside `"..."` strings, handle `\"` escapes)
5. Handles markdown code fence prefix (scan past ` ```json\n `)
6. On each complete `{...}` object at depth 0 in the array:
   - `JSON.parse` the extracted text
   - `VulnerabilitySchema.safeParse` to validate
   - If valid, add to returned array; if invalid, skip silently
7. Returns newly-parsed vulnerabilities from each `feed()` call

Export: `{ createIncrementalVulnerabilityParser, type IncrementalVulnerabilityParser }`

##### Verify
- `pnpm app:compile`

##### Timeout
120000

#### Step 2.2: Write Parser Unit Tests

Create file `test/unit/domain/audit/incrementalVulnerabilityParser.test.ts`.

Test cases (use `describe`/`it` from vitest globals, no imports needed):

1. **"parses complete JSON in single chunk"** — Feed a full valid JSON response with 3 vulnerabilities in one `feed()` call. Assert all 3 are returned.

2. **"parses vulnerabilities across multiple chunks"** — Split a valid JSON response into 5+ chunks (splitting mid-object). Assert each vulnerability is emitted only when its closing `}` arrives.

3. **"handles markdown code fence prefix"** — Feed text starting with ` ```json\n{...}``` `. Assert vulnerabilities are parsed correctly.

4. **"skips malformed vulnerability objects"** — Include one object with `level: "invalid_level"` (Zod validation failure). Assert it's skipped and the remaining valid objects are returned.

5. **"handles escaped braces in strings"** — Include a vulnerability with `description` containing `{` and `}` characters. Assert the parser doesn't break on them.

6. **"returns empty array when no vulnerabilities key"** — Feed text that doesn't contain a `"vulnerabilities"` key. Assert `feed()` always returns `[]`.

7. **"getParsedCount tracks total"** — Parse 3 vulns across multiple `feed()` calls. Assert `getParsedCount()` returns 3.

Use this valid vulnerability shape in test data:
```typescript
{
  category: 'authentication',
  level: 'critical',
  title: 'Hardcoded API Key',
  description: 'API key is hardcoded in source.',
  impact: 'Full account compromise',
  filePath: 'src/config.ts',
  fix: 'Use environment variables',
}
```

##### Verify
- `pnpm vitest run test/unit/domain/audit/incrementalVulnerabilityParser.test.ts --config vitest.config.unit.ts`

##### Timeout
120000

#### Gate
- `pnpm app:compile`
- `pnpm vitest run test/unit/domain/audit/incrementalVulnerabilityParser.test.ts --config vitest.config.unit.ts`

---

### Phase 3: Streaming Claude Client

> Gate: `pnpm app:compile`

#### Step 3.1: Add SSE Parser Utility

Create file `src/domain/audit/sseParser.ts`.

This is a pure function that parses Anthropic streaming SSE text into structured events. It handles buffering of partial lines across chunks.

```typescript
export interface SSEEvent {
  event: string;
  data: string;
}

export function createSSEParser(): {
  feed(chunk: string): SSEEvent[];
}
```

Implementation:
1. Maintain a buffer of incomplete lines
2. Split incoming chunk by `\n`
3. Track current `event` and `data` fields
4. On empty line (event boundary), emit the accumulated event
5. Lines starting with `event: ` set the event type
6. Lines starting with `data: ` set the data content
7. Return array of complete events from each `feed()` call

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 3.2: Write SSE Parser Tests

Create file `test/unit/domain/audit/sseParser.test.ts`.

Test cases:

1. **"parses single complete event"** — Feed a complete SSE event (`event: content_block_delta\ndata: {"type":"content_block_delta","delta":{"type":"text_delta","text":"hello"}}\n\n`). Assert one event is returned.

2. **"parses multiple events in one chunk"** — Feed two complete events in a single string. Assert both are returned.

3. **"buffers partial events across chunks"** — Split an event across two `feed()` calls. Assert the event is only emitted on the second call.

4. **"handles message_start event"** — Parse a `message_start` event with usage data. Assert correct event type and data.

5. **"handles message_stop event"** — Parse a `message_stop` event. Assert correct event type.

##### Verify
- `pnpm vitest run test/unit/domain/audit/sseParser.test.ts --config vitest.config.unit.ts`

##### Timeout
90000

#### Step 3.3: Add Streaming Analysis Function

Read `convex/clients/claude.ts`. Add a new exported function `runStreamingSecurityAnalysis` as specified in Section 4 of this spec.

Keep the existing `runSecurityAnalysis` function unchanged.

The new function:
1. Builds the same prompt as the existing function (reuse `buildAnalysisPrompt` and `SECURITY_ANALYST_SYSTEM_PROMPT`)
2. Makes a `fetch` call to `${ANTHROPIC_API_BASE}/v1/messages` with `stream: true` in the request body
3. Checks `response.ok` — if not, handle errors exactly like the existing function (429 → RATE_LIMIT, etc.)
4. Gets a `ReadableStream` reader from `response.body`
5. Creates an `SSEParser` and `IncrementalVulnerabilityParser`
6. In a `while(true)` loop:
   - Read chunks from the stream via `reader.read()`
   - Decode with `TextDecoder`
   - Feed to SSE parser
   - For `content_block_delta` events with `text_delta`: feed text to vulnerability parser, accumulate text
   - Throttle `callbacks.onTextDelta` calls (track `lastFlushTime`, only call if 1000ms elapsed or 200+ chars since last flush)
   - For each new vulnerability from parser: call `callbacks.onVulnerabilityParsed`
   - For `message_start`: extract `input_tokens` from `message.usage`
   - For `message_delta`: extract `output_tokens` from `usage`
   - For `message_stop`: call `callbacks.onComplete`, break loop
   - On `done === true` (stream ended): break
7. After loop: if `onComplete` hasn't been called yet, call it with accumulated data
8. Return `{ success: true, data: { vulnerabilities: allParsedVulns } }`
9. Wrap entire function in try/catch, call `callbacks.onError` on failure

Import the SSE parser from `../../src/domain/audit/sseParser` and the incremental vulnerability parser from `../../src/domain/audit/incrementalVulnerabilityParser`.

Also export `buildAnalysisPrompt` (change from module-private to exported) so `startAuditAction` can capture the prompt text for the inference record.

##### Verify
- `pnpm app:compile`

##### Timeout
180000

#### Gate
- `pnpm app:compile`

---

### Phase 4: Pipeline Integration

> Gate: `pnpm app:compile`

#### Step 4.1: Refactor Analysis Phase in startAuditAction

Read `convex/services/startAuditAction.ts`. Refactor the ANALYSIS PHASE section (the block between the "=== ANALYSIS PHASE ===" and "=== EVALUATION PHASE ===" comments, approximately lines 157-202) to use streaming.

**Changes:**

1. Add imports at the top of the file:
   - `import { runStreamingSecurityAnalysis, buildAnalysisPrompt } from '../clients/claude';`
   - `import { internal } from '../_generated/api';` (already imported)
   - Remove the import of `runSecurityAnalysis` (replace with `runStreamingSecurityAnalysis`)

2. Replace the analysis phase code with:

```typescript
// === ANALYSIS PHASE ===

if (isOverBudget(actionStart)) {
  await ctx.runMutation(internal.audits.fail, {
    auditId, error: 'Audit timed out during ingestion. Try a smaller repository.',
  });
  return;
}

await ctx.runMutation(internal.audits.updateStatus, { auditId, status: 'analyzing' });

// Create inference record for transparency
const promptText = buildAnalysisPrompt(files);
const inferenceId = await ctx.runMutation(internal.inferences.create, {
  auditId,
  agent: 'SECURITY_ANALYST',
  model: 'claude-sonnet-4-5-20250929',
  prompt: promptText,
});

let seqCounter = 0;
let lastFlushTime = Date.now();
const FLUSH_INTERVAL_MS = 1000;
const MIN_FLUSH_CHARS = 200;
let lastFlushedLength = 0;

const analysisResult = await runStreamingSecurityAnalysis(files, {
  onTextDelta: async (accumulatedText) => {
    const now = Date.now();
    const charsSinceFlush = accumulatedText.length - lastFlushedLength;
    if (now - lastFlushTime >= FLUSH_INTERVAL_MS && charsSinceFlush >= MIN_FLUSH_CHARS) {
      await ctx.runMutation(internal.inferences.updateStreamingText, {
        inferenceId,
        streamingText: accumulatedText,
      });
      lastFlushTime = now;
      lastFlushedLength = accumulatedText.length;
    }
  },

  onVulnerabilityParsed: async (vuln, _parserSeqNumber) => {
    seqCounter++;
    const sanitized = sanitizeVulnerabilities([vuln as Record<string, unknown>]);
    if (sanitized.length === 0) return;

    const v = sanitized[0];
    const displayId = generateDisplayId(auditId, seqCounter);

    const analysisId = await ctx.runMutation(internal.analyses.create, {
      auditId,
      seqNumber: seqCounter,
      displayId,
      category: v.category,
      level: v.level,
      title: v.title,
      description: v.description,
      impact: v.impact,
      filePath: v.filePath,
      fix: v.fix,
    });

    await ctx.runMutation(internal.auditEvents.create, {
      auditId,
      agent: 'SECURITY_ANALYST',
      message: generateAnalystMessage(v, displayId),
      analysisId,
    });
  },

  onComplete: async ({ fullResponse, inputTokens, outputTokens }) => {
    await ctx.runMutation(internal.inferences.complete, {
      inferenceId,
      response: fullResponse,
      inputTokens,
      outputTokens,
    });
  },

  onError: async (error) => {
    await ctx.runMutation(internal.inferences.fail, {
      inferenceId,
      error: error.message,
    });
  },
});

if (!analysisResult.success) {
  await ctx.runMutation(internal.audits.fail, { auditId, error: analysisResult.error.message });
  return;
}
```

3. Remove the old post-analysis vulnerability insertion loop (the `for (let i = 0; ...)` loop that used to iterate over `analysisResult.data.vulnerabilities`). The vulnerabilities are now inserted incrementally via `onVulnerabilityParsed`.

4. Keep the EVALUATION PHASE unchanged.

##### Verify
- `pnpm app:compile`

##### Timeout
180000

#### Gate
- `pnpm app:compile`

---

### Phase 5: Frontend Streaming Display

> Gate: `pnpm app:compile`

#### Step 5.1: Add Inference Subscription to SecurityAuditApp

Read `src/frontend/components/SecurityAuditApp.tsx`.

1. Add a new `useQuery` subscription after the existing ones (after the `evaluation` subscription, around line 82):

```typescript
const streamingInference = useQuery(
  api.inferences.getStreamingByAudit,
  currentAuditId ? { auditId: currentAuditId } : 'skip',
);
```

2. Update the `<AgentFeed>` component invocation (around line 331) to pass the streaming text:

Change from:
```tsx
<AgentFeed
  messages={messages}
  isAuditing={uiStatus === 'auditing' && !selectedCommitHash}
/>
```

To:
```tsx
<AgentFeed
  messages={messages}
  isAuditing={uiStatus === 'auditing' && !selectedCommitHash}
  streamingText={streamingInference?.streamingText ?? null}
/>
```

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 5.2: Update AgentFeed for Streaming Text

Read `src/frontend/components/AgentFeed.tsx`.

1. Add `streamingText` to `AgentFeedProps`:

```typescript
interface AgentFeedProps {
  messages: AgentMessage[];
  isAuditing: boolean;
  streamingText: string | null;
}
```

2. Update the component signature to destructure `streamingText`:

```typescript
export function AgentFeed({ messages, isAuditing, streamingText }: AgentFeedProps)
```

3. Update the auto-scroll `useEffect` to also trigger on `streamingText`:

```typescript
useEffect(() => {
  if (scrollRef.current) {
    scrollRef.current.scrollTop = scrollRef.current.scrollHeight;
  }
}, [messages, streamingText]);
```

4. Add a streaming text block inside the `<div className="flex flex-col">`, after the `</AnimatePresence>` closing tag and before the empty state check (`{messages.length === 0 && ...}`):

```tsx
{streamingText && (
  <motion.div
    key="streaming-text"
    initial={{ opacity: 0 }}
    animate={{ opacity: 1 }}
    className="flex gap-4 border-b border-[#1C2430]/50 p-4 bg-emerald-500/5"
  >
    <div className="shrink-0 pt-1">
      <div className="flex h-8 w-8 items-center justify-center rounded-lg border bg-emerald-500/10 border-emerald-500/30 text-emerald-400">
        <ShieldAlert className="h-4 w-4" />
      </div>
    </div>
    <div className="min-w-0 flex-1">
      <div className="mb-1 flex items-center gap-2">
        <span className="text-xs font-bold uppercase tracking-wider text-emerald-400">
          Security Analyst
        </span>
        <span className="text-[10px] text-emerald-400/60 animate-pulse">
          analyzing...
        </span>
      </div>
      <pre className="whitespace-pre-wrap font-sans text-xs font-light leading-relaxed text-[#E6EEF8]/70 max-h-48 overflow-y-auto">
        {streamingText}
      </pre>
    </div>
  </motion.div>
)}
```

`ShieldAlert` is already imported at the top of the file.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Gate
- `pnpm app:compile`

---

### Phase 6: Validation

> Gate: `pnpm app:compile && pnpm test:unit:ci`

#### Step 6.1: Run Full Test Suite

Run the full unit test suite to verify no regressions.

##### Verify
- `pnpm app:compile`
- `pnpm test:unit:ci`

##### Timeout
120000

---

## 13. Change Log

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-02-21 | Initial specification |
