# Server Scaffolding: Technical Specification

**Version**: 1.0.0
**Status**: Draft
**Author**: Architect Agent
**Date**: 2026-02-21

---

## 1. Overview

### 1.1 Objective

Scaffold the Convex backend for Vibesafe: schema definition, external API client wrappers (GitHub REST API, Anthropic Messages API), CRUD functions, audit service orchestration action, and Next.js Convex provider integration.

### 1.2 Constraints

- Server doctrine: `docs/doctrine/architecture/server/server-doctrine.md`
- Database doctrine: `docs/doctrine/architecture/db/database-doctrine.md`
- Ingestion protocol: `docs/protocol/ingestion/ingestion-protocol.md.md`
- Audit protocol: `docs/protocol/audit/audit-protocol.md`
- No unit tests in this spec
- All npm dependencies pre-installed (`convex@^1.32.0`, `zod@^4.3.6`)
- API keys assumed available in `.env`

### 1.3 Success Criteria

- `pnpm app:compile` passes
- `pnpm app:lint` passes

### 1.4 Key Deviation from Doctrine

The server doctrine references "MinMax" as the analysis agent. This spec replaces MinMax with the **Anthropic Messages API** (Claude) per stakeholder decision. The doctrine will be updated separately after this spec executes.

---

## 2. Scope

| In Scope | Out of Scope |
|----------|--------------|
| Convex schema definition (4 tables) | Unit/integration tests |
| GitHub REST API client wrapper | Retrvr.ai client |
| Anthropic Messages API client wrapper | Authentication setup (Clerk/Auth.js) |
| Convex CRUD functions (audits, analyses, evaluations, events) | Convex deployment/provisioning |
| Audit service orchestration action | Frontend feature integration (beyond provider) |
| ConvexClientProvider for Next.js | CI/CD configuration |
| `.env.example` updates | Server doctrine updates |
| Build config updates (tsconfig, eslint, gitignore) | |

---

## 3. Architecture

```
+---------------------------------------------------------------+
|                      Convex Actions                           |
+---------------------------------------------------------------+
|                                                               |
|  +-------------------------------------------------------+   |
|  |                   Audit Service                        |   |
|  |            (orchestrates the audit flow)               |   |
|  +---------------------+--------------------------------+   |
|                         |                                     |
|         +---------------+---------------+                     |
|         v                               v                     |
|  +--------------+              +--------------+               |
|  |   GitHub     |              |   Claude     |               |
|  |   Client     |              |   Client     |               |
|  +--------------+              +--------------+               |
|                                                               |
+---------------------------------------------------------------+
```

### 3.1 Directory Structure

```
convex/
  schema.ts                  # Convex table definitions
  audits.ts                  # Audit CRUD (queries, mutations)
  analyses.ts                # Analysis CRUD
  evaluations.ts             # Evaluation CRUD
  auditEvents.ts             # Audit event CRUD (activity feed)
  clients/
    github.ts                # GitHub REST API wrapper
    claude.ts                # Anthropic Messages API wrapper
  services/
    schemas.ts               # Zod schemas for external API responses
    auditService.ts          # Audit orchestration action
  _generated/                # Auto-generated by npx convex dev (gitignored)

src/frontend/
  providers/
    ConvexClientProvider.tsx  # Convex React provider (client component)
```

---

## 4. Data Model

Reconciled from database doctrine, ingestion protocol, and audit protocol.

### 4.1 `audits` Table

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `repoUrl` | `string` | Yes | Original GitHub URL |
| `repoOwner` | `string` | Yes | Parsed owner from URL |
| `repoName` | `string` | Yes | Parsed repo name |
| `commitHash` | `string` | Yes | SHA from GitHub tree response |
| `status` | `union` | Yes | One of: `pending`, `fetching`, `analyzing`, `evaluating`, `complete`, `failed` |
| `userId` | `string` | No | GitHub user or anonymous |
| `truncated` | `boolean` | No | Whether repo content was truncated |
| `stats` | `object` | No | `{ totalFiles, includedFiles, totalTokens, includedTokens }` (all `number`) |
| `error` | `string` | No | Error message when status = `failed` |

**Indexes:** `by_user[userId]`, `by_repo[repoOwner, repoName]`, `by_url[repoUrl]`

### 4.2 `audit_analyses` Table

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `auditId` | `id("audits")` | Yes | Parent audit |
| `seqNumber` | `number` | Yes | 1-indexed sequence within audit |
| `displayId` | `string` | Yes | Human-readable ID, e.g. `SEC-A-001` |
| `category` | `string` | Yes | e.g. `authentication`, `injection` |
| `level` | `union` | Yes | One of: `low`, `medium`, `high`, `critical` |
| `title` | `string` | Yes | Short vulnerability description |
| `description` | `string` | Yes | Detailed explanation |
| `filePath` | `string` | No | File containing vulnerability |
| `fix` | `string` | No | Recommended remediation |
| `links` | `array(string)` | No | Related CVE/hack URLs (future) |

**Indexes:** `by_audit[auditId]`

### 4.3 `audit_evaluations` Table

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `auditId` | `id("audits")` | Yes | Parent audit |
| `probability` | `number` | Yes | 0-100 safety score |
| `executiveSummary` | `string` | Yes | Human-readable summary |

**Indexes:** `by_audit[auditId]`

### 4.4 `audit_events` Table

| Field | Type | Required | Description |
|-------|------|----------|-------------|
| `auditId` | `id("audits")` | Yes | Parent audit |
| `agent` | `union` | Yes | `SECURITY_ANALYST` or `EVALUATOR` |
| `message` | `string` | Yes | Event message for activity feed |
| `analysisId` | `id("audit_analyses")` | No | Linked analysis (analyst events only) |

**Indexes:** `by_audit[auditId]`

---

## 5. Client Specifications

### 5.1 GitHub Client (`convex/clients/github.ts`)

**Base URL:** `https://api.github.com`
**Auth:** `Authorization: Bearer ${process.env.GITHUB_API_KEY}`

**Functions:**

| Function | Args | Returns | Description |
|----------|------|---------|-------------|
| `fetchRepoTree` | `owner, repo, branch?` | `GitHubClientResult<GitHubTreeResponse>` | GET `/repos/{owner}/{repo}/git/trees/{branch}?recursive=1` |
| `fetchBlob` | `owner, repo, sha` | `GitHubClientResult<GitHubBlobResponse>` | GET `/repos/{owner}/{repo}/git/blobs/{sha}` |

**Error codes:** `NOT_FOUND` (404), `PRIVATE_REPO` (403 non-rate-limit), `RATE_LIMIT` (403 with X-RateLimit-Remaining=0), `GITHUB_ERROR` (other), `NETWORK_ERROR` (fetch failure)

### 5.2 Claude Client (`convex/clients/claude.ts`)

**Base URL:** `https://api.anthropic.com`
**Auth:** `x-api-key: ${process.env.CLAUDE_CODE_API_KEY}` + `anthropic-version: 2023-06-01`
**Model:** `claude-sonnet-4-5-20250929`

**Functions:**

| Function | Args | Returns | Description |
|----------|------|---------|-------------|
| `runSecurityAnalysis` | `files: { path, content }[]` | `ClaudeClientResult<{ vulnerabilities: Vulnerability[] }>` | POST `/v1/messages` with security analyst system prompt |

**Error codes:** `RATE_LIMIT` (429), `CLAUDE_ERROR` (other HTTP error), `INVALID_RESPONSE` (Zod validation failure or non-JSON), `NETWORK_ERROR` (fetch failure)

### 5.3 Result Type Convention

All clients return structured results and MUST NOT throw:

```typescript
type ClientResult<T> =
  | { success: true; data: T }
  | { success: false; error: { code: string; message: string } };
```

---

## 6. Environment Variables

```bash
# .env.example
GITHUB_API_KEY=""              # GitHub personal access token (server-side, set in Convex dashboard)
CLAUDE_CODE_API_KEY=""         # Anthropic API key (server-side, set in Convex dashboard)
NEXT_PUBLIC_CONVEX_URL=""      # Convex deployment URL (client-side, from npx convex dev)
```

- `GITHUB_API_KEY` and `CLAUDE_CODE_API_KEY` are accessed via `process.env` in Convex actions
- `NEXT_PUBLIC_CONVEX_URL` is used by the Next.js ConvexClientProvider

---

## 7. Prompt Execution Strategy

### Phase 1: Build Configuration

> Gate: `pnpm app:compile && pnpm app:lint`

#### Step 1.1: Update tsconfig.json

Add `"convex"` to the `exclude` array in `tsconfig.json`. Convex has its own TypeScript compilation pipeline via `npx convex dev` and must be excluded from the main Next.js TypeScript project.

**Current `exclude`:**
```json
"exclude": ["node_modules", "scripts/orchestrator", "prototype"]
```

**Target `exclude`:**
```json
"exclude": ["node_modules", "scripts/orchestrator", "prototype", "convex"]
```

Use the Edit tool to make this change.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 1.2: Update eslint.config.mjs

Add `"convex/**"` to the `ignores` array in the first config object of `eslint.config.mjs`. Convex functions use generated imports that aren't part of the main ESLint TypeScript project.

**Current ignores array (lines 16-28):**
```javascript
ignores: [
  ".next/**",
  ".storybook/**",
  "storybook-static/**",
  "coverage/**",
  "postcss.config.mjs",
  "out/**",
  "build/**",
  "prototype/**",
  "infra/**",
  "supabase/**",
  ".orchestrator",
],
```

**Add `"convex/**"` to the end of this array.**

Use the Edit tool.

##### Verify
- `pnpm app:lint`

##### Timeout
90000

#### Step 1.3: Update .gitignore

Add the following line to `.gitignore` (after the `# typescript` section):

```
# convex
convex/_generated
```

Use the Edit tool to append after the existing content.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 2: Convex Schema and Zod Validation

> Gate: `pnpm app:compile`

#### Step 2.1: Create convex/schema.ts

Create the directory `convex/` and write `convex/schema.ts` with the full Convex schema.

```typescript
import { defineSchema, defineTable } from 'convex/server';
import { v } from 'convex/values';

export default defineSchema({
  audits: defineTable({
    repoUrl: v.string(),
    repoOwner: v.string(),
    repoName: v.string(),
    commitHash: v.string(),
    status: v.union(
      v.literal('pending'),
      v.literal('fetching'),
      v.literal('analyzing'),
      v.literal('evaluating'),
      v.literal('complete'),
      v.literal('failed'),
    ),
    userId: v.optional(v.string()),
    truncated: v.optional(v.boolean()),
    stats: v.optional(
      v.object({
        totalFiles: v.number(),
        includedFiles: v.number(),
        totalTokens: v.number(),
        includedTokens: v.number(),
      }),
    ),
    error: v.optional(v.string()),
  })
    .index('by_user', ['userId'])
    .index('by_repo', ['repoOwner', 'repoName'])
    .index('by_url', ['repoUrl']),

  audit_analyses: defineTable({
    auditId: v.id('audits'),
    seqNumber: v.number(),
    displayId: v.string(),
    category: v.string(),
    level: v.union(
      v.literal('low'),
      v.literal('medium'),
      v.literal('high'),
      v.literal('critical'),
    ),
    title: v.string(),
    description: v.string(),
    filePath: v.optional(v.string()),
    fix: v.optional(v.string()),
    links: v.optional(v.array(v.string())),
  }).index('by_audit', ['auditId']),

  audit_evaluations: defineTable({
    auditId: v.id('audits'),
    probability: v.number(),
    executiveSummary: v.string(),
  }).index('by_audit', ['auditId']),

  audit_events: defineTable({
    auditId: v.id('audits'),
    agent: v.union(
      v.literal('SECURITY_ANALYST'),
      v.literal('EVALUATOR'),
    ),
    message: v.string(),
    analysisId: v.optional(v.id('audit_analyses')),
  }).index('by_audit', ['auditId']),
});
```

Use the Write tool to create this file. Create the `convex/` directory first if needed.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 2.2: Create convex/services/schemas.ts

Create `convex/services/` directory and write the Zod validation schemas for external API responses.

```typescript
import { z } from 'zod';

export const VulnerabilitySchema = z.object({
  category: z.string(),
  level: z.enum(['low', 'medium', 'high', 'critical']),
  title: z.string(),
  description: z.string(),
  filePath: z.string().optional(),
  fix: z.string().optional(),
});

export const ClaudeAnalysisResponseSchema = z.object({
  vulnerabilities: z.array(VulnerabilitySchema),
});

export type Vulnerability = z.infer<typeof VulnerabilitySchema>;
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 3: External API Clients

> Gate: `pnpm app:compile`

#### Step 3.1: Create convex/clients/github.ts

Create `convex/clients/` directory and write the GitHub REST API client. This client wraps the GitHub Trees and Blobs APIs for fetching repository contents.

All functions return structured results (`{ success, data } | { success, error }`) and MUST NOT throw.

```typescript
const GITHUB_API_BASE = 'https://api.github.com';

export interface GitHubTreeEntry {
  path: string;
  mode: string;
  type: 'blob' | 'tree';
  sha: string;
  size?: number;
}

export interface GitHubTreeResponse {
  sha: string;
  tree: GitHubTreeEntry[];
  truncated: boolean;
}

export interface GitHubBlobResponse {
  content: string;
  encoding: 'base64' | 'utf-8';
  size: number;
}

type GitHubClientResult<T> =
  | { success: true; data: T }
  | { success: false; error: { code: string; message: string } };

function getHeaders(): Record<string, string> {
  const headers: Record<string, string> = {
    Accept: 'application/vnd.github.v3+json',
  };
  if (process.env.GITHUB_API_KEY) {
    headers.Authorization = `Bearer ${process.env.GITHUB_API_KEY}`;
  }
  return headers;
}

export async function fetchRepoTree(
  owner: string,
  repo: string,
  branch = 'HEAD',
): Promise<GitHubClientResult<GitHubTreeResponse>> {
  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${owner}/${repo}/git/trees/${branch}?recursive=1`,
      { headers: getHeaders() },
    );

    if (!response.ok) {
      if (response.status === 404) {
        return {
          success: false,
          error: { code: 'NOT_FOUND', message: 'Repository not found' },
        };
      }
      if (response.status === 403) {
        const rateLimitRemaining =
          response.headers.get('X-RateLimit-Remaining');
        if (rateLimitRemaining === '0') {
          const resetTime = response.headers.get('X-RateLimit-Reset');
          const minutes = resetTime
            ? Math.ceil((Number(resetTime) * 1000 - Date.now()) / 60000)
            : 0;
          return {
            success: false,
            error: {
              code: 'RATE_LIMIT',
              message: `GitHub rate limit hit. Try again in ${minutes} minutes.`,
            },
          };
        }
        return {
          success: false,
          error: {
            code: 'PRIVATE_REPO',
            message: 'Repository is private or inaccessible',
          },
        };
      }
      return {
        success: false,
        error: {
          code: 'GITHUB_ERROR',
          message: `GitHub API error: ${response.status}`,
        },
      };
    }

    const data = (await response.json()) as GitHubTreeResponse;
    return { success: true, data };
  } catch (error) {
    return {
      success: false,
      error: {
        code: 'NETWORK_ERROR',
        message: error instanceof Error ? error.message : 'Unknown error',
      },
    };
  }
}

export async function fetchBlob(
  owner: string,
  repo: string,
  sha: string,
): Promise<GitHubClientResult<GitHubBlobResponse>> {
  try {
    const response = await fetch(
      `${GITHUB_API_BASE}/repos/${owner}/${repo}/git/blobs/${sha}`,
      { headers: getHeaders() },
    );

    if (!response.ok) {
      return {
        success: false,
        error: {
          code: 'GITHUB_ERROR',
          message: `GitHub API error: ${response.status}`,
        },
      };
    }

    const data = (await response.json()) as GitHubBlobResponse;
    return { success: true, data };
  } catch (error) {
    return {
      success: false,
      error: {
        code: 'NETWORK_ERROR',
        message: error instanceof Error ? error.message : 'Unknown error',
      },
    };
  }
}
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 3.2: Create convex/clients/claude.ts

Write the Anthropic Messages API client for security analysis. This replaces the MinMax client from the server doctrine.

**API details:**
- Endpoint: `POST https://api.anthropic.com/v1/messages`
- Auth: `x-api-key` header (NOT `Authorization: Bearer`)
- Version: `anthropic-version: 2023-06-01`
- Model: `claude-sonnet-4-5-20250929`
- Response: `{ content: [{ type: "text", text: "..." }] }` — parse `text` as JSON

The system prompt instructs Claude to return a JSON object with a `vulnerabilities` array. The response text is parsed as JSON and validated with `ClaudeAnalysisResponseSchema` from `../services/schemas`.

```typescript
import { z } from 'zod';

import {
  ClaudeAnalysisResponseSchema,
  type Vulnerability,
} from '../services/schemas';

const ANTHROPIC_API_BASE = 'https://api.anthropic.com';
const ANTHROPIC_VERSION = '2023-06-01';
const DEFAULT_MODEL = 'claude-sonnet-4-5-20250929';

type ClaudeClientResult<T> =
  | { success: true; data: T }
  | { success: false; error: { code: string; message: string } };

const SECURITY_ANALYST_SYSTEM_PROMPT = `You are an expert security analyst reviewing codebases for vulnerabilities.

Your task is to identify security vulnerabilities in the provided code.

For each vulnerability found, provide:
- category: The type of vulnerability (e.g., "authentication", "authorization", "injection", "exposure", "cryptography", "configuration")
- level: Severity as one of: "low", "medium", "high", "critical"
- title: A short, descriptive title
- description: A detailed explanation of the vulnerability and its impact
- filePath: The file path where the vulnerability exists (if applicable, omit if architectural)
- fix: A recommended remediation (if applicable)

Severity guidelines:
- critical: Immediate exploitation possible, severe impact (data breach, financial loss, RCE)
- high: Exploitation likely, significant impact (privilege escalation, sensitive data exposure)
- medium: Exploitation possible with effort, moderate impact (information disclosure, DoS)
- low: Minor issues, limited impact (best practice violations, minor info leaks)

Respond with a JSON object containing a "vulnerabilities" array. If no vulnerabilities are found, return an empty array.

Example response:
{
  "vulnerabilities": [
    {
      "category": "authentication",
      "level": "critical",
      "title": "Unauthenticated Payment Session Creation",
      "description": "The endpoint accepts userId directly from the request body without verifying the caller's identity.",
      "filePath": "/api/create-checkout-session.ts",
      "fix": "Replace client-provided userId with server-side session authentication."
    }
  ]
}`;

function buildAnalysisPrompt(
  files: { path: string; content: string }[],
): string {
  const fileContents = files
    .map((f) => `// File: ${f.path}\n${f.content}`)
    .join('\n\n---\n\n');

  return `Analyze the following codebase for security vulnerabilities:\n\n${fileContents}\n\nIdentify all security vulnerabilities and respond with JSON.`;
}

const AnthropicMessageSchema = z.object({
  content: z.array(
    z.object({
      type: z.literal('text'),
      text: z.string(),
    }),
  ),
});

export async function runSecurityAnalysis(
  files: { path: string; content: string }[],
): Promise<ClaudeClientResult<{ vulnerabilities: Vulnerability[] }>> {
  try {
    const response = await fetch(`${ANTHROPIC_API_BASE}/v1/messages`, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'x-api-key': process.env.CLAUDE_CODE_API_KEY ?? '',
        'anthropic-version': ANTHROPIC_VERSION,
      },
      body: JSON.stringify({
        model: DEFAULT_MODEL,
        max_tokens: 8192,
        system: SECURITY_ANALYST_SYSTEM_PROMPT,
        messages: [
          {
            role: 'user',
            content: buildAnalysisPrompt(files),
          },
        ],
      }),
    });

    if (!response.ok) {
      if (response.status === 429) {
        return {
          success: false,
          error: {
            code: 'RATE_LIMIT',
            message: 'Anthropic rate limit exceeded',
          },
        };
      }
      return {
        success: false,
        error: {
          code: 'CLAUDE_ERROR',
          message: `Anthropic API error: ${response.status}`,
        },
      };
    }

    const raw = await response.json();

    const anthropicParsed = AnthropicMessageSchema.safeParse(raw);
    if (!anthropicParsed.success) {
      return {
        success: false,
        error: {
          code: 'INVALID_RESPONSE',
          message: 'Invalid Anthropic response shape',
        },
      };
    }

    const textContent = anthropicParsed.data.content[0]?.text;
    if (!textContent) {
      return {
        success: false,
        error: {
          code: 'INVALID_RESPONSE',
          message: 'Empty response from Claude',
        },
      };
    }

    let analysisJson: unknown;
    try {
      analysisJson = JSON.parse(textContent);
    } catch {
      return {
        success: false,
        error: {
          code: 'INVALID_RESPONSE',
          message: 'Claude response is not valid JSON',
        },
      };
    }

    const analysisParsed =
      ClaudeAnalysisResponseSchema.safeParse(analysisJson);
    if (!analysisParsed.success) {
      return {
        success: false,
        error: {
          code: 'INVALID_RESPONSE',
          message: analysisParsed.error.message,
        },
      };
    }

    return { success: true, data: analysisParsed.data };
  } catch (error) {
    return {
      success: false,
      error: {
        code: 'NETWORK_ERROR',
        message: error instanceof Error ? error.message : 'Unknown error',
      },
    };
  }
}
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 4: Convex CRUD Functions

> Gate: `pnpm app:compile`

#### Step 4.1: Create convex/audits.ts

Write the audit CRUD functions. Public queries/mutations for frontend use, internal mutations for service-to-service calls.

**Imports:** `v` from `convex/values`, `query`, `mutation`, `internalMutation`, `internalQuery` from `./_generated/server`.

**Functions:**
- `create` (mutation): Insert new audit with status `pending`, optional userId from auth
- `get` (query): Get audit by ID, throw `NOT_FOUND` if missing
- `getInternal` (internalQuery): Get audit by ID, return null if missing
- `listByRepo` (query): List audits by `repoUrl`, ordered descending
- `updateStatus` (internalMutation): Patch audit status
- `fail` (internalMutation): Set status to `failed` with error message
- `updateIngestStats` (internalMutation): Patch commitHash, truncated, stats

```typescript
import { v } from 'convex/values';

import {
  internalMutation,
  internalQuery,
  mutation,
  query,
} from './_generated/server';

export const create = mutation({
  args: {
    repoUrl: v.string(),
    repoOwner: v.string(),
    repoName: v.string(),
    commitHash: v.string(),
  },
  handler: async (ctx, args) => {
    const identity = await ctx.auth.getUserIdentity();

    return await ctx.db.insert('audits', {
      ...args,
      status: 'pending',
      userId: identity?.subject ?? undefined,
    });
  },
});

export const get = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    const audit = await ctx.db.get(auditId);
    if (!audit) throw new Error('NOT_FOUND');
    return audit;
  },
});

export const getInternal = internalQuery({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    return await ctx.db.get(auditId);
  },
});

export const listByRepo = query({
  args: { repoUrl: v.string() },
  handler: async (ctx, { repoUrl }) => {
    return await ctx.db
      .query('audits')
      .withIndex('by_url', (q) => q.eq('repoUrl', repoUrl))
      .order('desc')
      .collect();
  },
});

export const updateStatus = internalMutation({
  args: {
    auditId: v.id('audits'),
    status: v.union(
      v.literal('pending'),
      v.literal('fetching'),
      v.literal('analyzing'),
      v.literal('evaluating'),
      v.literal('complete'),
      v.literal('failed'),
    ),
  },
  handler: async (ctx, { auditId, status }) => {
    await ctx.db.patch(auditId, { status });
  },
});

export const fail = internalMutation({
  args: {
    auditId: v.id('audits'),
    error: v.string(),
  },
  handler: async (ctx, { auditId, error }) => {
    await ctx.db.patch(auditId, { status: 'failed' as const, error });
  },
});

export const updateIngestStats = internalMutation({
  args: {
    auditId: v.id('audits'),
    commitHash: v.string(),
    truncated: v.boolean(),
    stats: v.object({
      totalFiles: v.number(),
      includedFiles: v.number(),
      totalTokens: v.number(),
      includedTokens: v.number(),
    }),
  },
  handler: async (ctx, { auditId, commitHash, truncated, stats }) => {
    await ctx.db.patch(auditId, { commitHash, truncated, stats });
  },
});
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 4.2: Create convex/analyses.ts

Write analysis CRUD functions.

**Functions:**
- `create` (internalMutation): Insert new analysis (called from audit service)
- `listByAudit` (query): List analyses for an audit (used by frontend feed)

```typescript
import { v } from 'convex/values';

import { internalMutation, query } from './_generated/server';

export const create = internalMutation({
  args: {
    auditId: v.id('audits'),
    seqNumber: v.number(),
    displayId: v.string(),
    category: v.string(),
    level: v.union(
      v.literal('low'),
      v.literal('medium'),
      v.literal('high'),
      v.literal('critical'),
    ),
    title: v.string(),
    description: v.string(),
    filePath: v.optional(v.string()),
    fix: v.optional(v.string()),
    links: v.optional(v.array(v.string())),
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert('audit_analyses', args);
  },
});

export const listByAudit = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    return await ctx.db
      .query('audit_analyses')
      .withIndex('by_audit', (q) => q.eq('auditId', auditId))
      .collect();
  },
});
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 4.3: Create convex/evaluations.ts

Write evaluation CRUD functions.

**Functions:**
- `create` (internalMutation): Insert new evaluation
- `getByAudit` (query): Get evaluation for an audit (returns first match or null)

```typescript
import { v } from 'convex/values';

import { internalMutation, query } from './_generated/server';

export const create = internalMutation({
  args: {
    auditId: v.id('audits'),
    probability: v.number(),
    executiveSummary: v.string(),
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert('audit_evaluations', args);
  },
});

export const getByAudit = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    return await ctx.db
      .query('audit_evaluations')
      .withIndex('by_audit', (q) => q.eq('auditId', auditId))
      .first();
  },
});
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 4.4: Create convex/auditEvents.ts

Write audit event CRUD functions for the real-time activity feed.

**Functions:**
- `create` (internalMutation): Insert new event (called from audit service)
- `listByAudit` (query): List events for an audit, ordered ascending (oldest first, chronological feed)

```typescript
import { v } from 'convex/values';

import { internalMutation, query } from './_generated/server';

export const create = internalMutation({
  args: {
    auditId: v.id('audits'),
    agent: v.union(
      v.literal('SECURITY_ANALYST'),
      v.literal('EVALUATOR'),
    ),
    message: v.string(),
    analysisId: v.optional(v.id('audit_analyses')),
  },
  handler: async (ctx, args) => {
    return await ctx.db.insert('audit_events', args);
  },
});

export const listByAudit = query({
  args: { auditId: v.id('audits') },
  handler: async (ctx, { auditId }) => {
    return await ctx.db
      .query('audit_events')
      .withIndex('by_audit', (q) => q.eq('auditId', auditId))
      .order('asc')
      .collect();
  },
});
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 5: Service Layer

> Gate: `pnpm app:compile`

#### Step 5.1: Create convex/services/auditService.ts

Write the audit orchestration action. This is the core service that coordinates the security analysis flow:

1. Update status to `analyzing`
2. Call Claude client for security analysis
3. Store each vulnerability as an `audit_analyses` row + create `audit_events` feed entry
4. Update status to `evaluating`
5. Calculate safety probability (deterministic scoring)
6. Generate executive summary (template-based)
7. Store evaluation
8. Create evaluator feed event
9. Mark complete

**Pure functions (no external calls):**
- `calculateSafetyProbability`: Penalties — critical=40, high=25, medium=10, low=5. Result = max(0, min(100, 100 - totalPenalty))
- `generateExecutiveSummary`: Template-based summary with severity counts, affected areas, and verdict
- `generateDisplayId`: Format `SEC-{firstCharOfAuditId}-{paddedSeqNumber}`
- `generateAnalystMessage`: Natural language message for feed

```typescript
import { v } from 'convex/values';

import { action } from '../_generated/server';
import { internal } from '../_generated/api';
import { runSecurityAnalysis } from '../clients/claude';
import type { Vulnerability } from './schemas';

const SEVERITY_PENALTIES: Record<string, number> = {
  critical: 40,
  high: 25,
  medium: 10,
  low: 5,
};

function calculateSafetyProbability(
  vulnerabilities: { level: string }[],
): number {
  if (vulnerabilities.length === 0) return 100;

  const totalPenalty = vulnerabilities.reduce(
    (sum, v) => sum + (SEVERITY_PENALTIES[v.level] ?? 0),
    0,
  );

  return Math.max(0, Math.min(100, 100 - totalPenalty));
}

function generateExecutiveSummary(
  vulnerabilities: { level: string; category: string }[],
): string {
  if (vulnerabilities.length === 0) {
    return 'No security vulnerabilities detected. This codebase appears safe for deployment.';
  }

  const counts = {
    critical: vulnerabilities.filter((v) => v.level === 'critical').length,
    high: vulnerabilities.filter((v) => v.level === 'high').length,
    medium: vulnerabilities.filter((v) => v.level === 'medium').length,
    low: vulnerabilities.filter((v) => v.level === 'low').length,
  };

  const severityParts: string[] = [];
  if (counts.critical > 0) severityParts.push(`${counts.critical} Critical`);
  if (counts.high > 0) severityParts.push(`${counts.high} High`);
  if (counts.medium > 0) severityParts.push(`${counts.medium} Medium`);
  if (counts.low > 0) severityParts.push(`${counts.low} Low`);
  const severitySummary = severityParts.join(' and ');

  const categories = [
    ...new Set(vulnerabilities.map((v) => v.category)),
  ];
  const areaSummary = categories.slice(0, 3).join(', ');

  let verdict: string;
  if (counts.critical > 0) {
    verdict = 'Deployment unsafe.';
  } else if (counts.high > 0) {
    verdict = 'Deployment not recommended until issues are resolved.';
  } else if (counts.medium > 0) {
    verdict = 'Deployment acceptable with caution. Address issues soon.';
  } else {
    verdict = 'Deployment acceptable. Consider addressing minor issues.';
  }

  return `Audit Complete. ${severitySummary} severity vulnerabilities found. Affected areas: ${areaSummary}. ${verdict}`;
}

function generateDisplayId(
  auditId: string,
  seqNumber: number,
): string {
  const shortId = auditId.slice(0, 1).toUpperCase();
  const seq = String(seqNumber).padStart(3, '0');
  return `SEC-${shortId}-${seq}`;
}

function generateAnalystMessage(
  vuln: Vulnerability,
  displayId: string,
): string {
  const severityLabel =
    vuln.level.charAt(0).toUpperCase() + vuln.level.slice(1);
  const fileRef = vuln.filePath ? ` in ${vuln.filePath}` : '';
  const firstSentence = vuln.description.split('.')[0];
  return `Found ${vuln.title}${fileRef}. ${firstSentence}. This is a ${severityLabel} ${vuln.category} vulnerability (${displayId}).`;
}

type AuditResult =
  | {
      success: true;
      data: { vulnerabilityCount: number; probability: number };
    }
  | { success: false; error: { code: string; message: string } };

export const runAudit = action({
  args: {
    auditId: v.id('audits'),
    files: v.array(
      v.object({
        path: v.string(),
        content: v.string(),
      }),
    ),
  },
  handler: async (ctx, { auditId, files }): Promise<AuditResult> => {
    // 1. Update status to analyzing
    await ctx.runMutation(internal.audits.updateStatus, {
      auditId,
      status: 'analyzing',
    });

    // 2. Call Claude for security analysis
    const analysisResult = await runSecurityAnalysis(files);
    if (!analysisResult.success) {
      await ctx.runMutation(internal.audits.fail, {
        auditId,
        error: analysisResult.error.message,
      });
      return { success: false, error: analysisResult.error };
    }

    const vulnerabilities = analysisResult.data.vulnerabilities;

    // 3. Store each vulnerability + create feed event
    for (let i = 0; i < vulnerabilities.length; i++) {
      const vuln = vulnerabilities[i];
      const seqNumber = i + 1;
      const displayId = generateDisplayId(auditId, seqNumber);

      const analysisId = await ctx.runMutation(
        internal.analyses.create,
        {
          auditId,
          seqNumber,
          displayId,
          category: vuln.category,
          level: vuln.level,
          title: vuln.title,
          description: vuln.description,
          filePath: vuln.filePath,
          fix: vuln.fix,
        },
      );

      await ctx.runMutation(internal.auditEvents.create, {
        auditId,
        agent: 'SECURITY_ANALYST',
        message: generateAnalystMessage(vuln, displayId),
        analysisId,
      });
    }

    // 4. Update status to evaluating
    await ctx.runMutation(internal.audits.updateStatus, {
      auditId,
      status: 'evaluating',
    });

    // 5. Calculate probability + generate summary
    const probability = calculateSafetyProbability(vulnerabilities);
    const executiveSummary = generateExecutiveSummary(vulnerabilities);

    // 6. Store evaluation
    await ctx.runMutation(internal.evaluations.create, {
      auditId,
      probability,
      executiveSummary,
    });

    // 7. Create evaluator feed event
    await ctx.runMutation(internal.auditEvents.create, {
      auditId,
      agent: 'EVALUATOR',
      message: executiveSummary,
    });

    // 8. Mark complete
    await ctx.runMutation(internal.audits.updateStatus, {
      auditId,
      status: 'complete',
    });

    return {
      success: true,
      data: {
        vulnerabilityCount: vulnerabilities.length,
        probability,
      },
    };
  },
});
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 6: Next.js Integration

> Gate: `pnpm app:compile && pnpm app:lint`

#### Step 6.1: Create src/frontend/providers/ConvexClientProvider.tsx

Create the `src/frontend/providers/` directory and write the Convex React provider as a client component.

This component:
- Creates a `ConvexReactClient` using `NEXT_PUBLIC_CONVEX_URL`
- Wraps children with `ConvexProvider` from the `convex` npm package (NOT from `convex/_generated/`)
- Is marked `'use client'` since it uses React context

```tsx
'use client';

import { ConvexProvider, ConvexReactClient } from 'convex/react';

const convex = new ConvexReactClient(
  process.env.NEXT_PUBLIC_CONVEX_URL!,
);

export function ConvexClientProvider({
  children,
}: {
  children: React.ReactNode;
}) {
  return <ConvexProvider client={convex}>{children}</ConvexProvider>;
}
```

Use the Write tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

#### Step 6.2: Update app/layout.tsx

Read `app/layout.tsx`. Import `ConvexClientProvider` and wrap the `{children}` in the body with it.

**Import to add** (after existing imports):
```typescript
import { ConvexClientProvider } from '@/src/frontend/providers/ConvexClientProvider';
```

**Body change:** Replace `{children}` inside the `<body>` with:
```tsx
<ConvexClientProvider>{children}</ConvexClientProvider>
```

The layout remains a Server Component — the ConvexClientProvider is a Client Component that provides context to its children.

Use the Edit tool for both changes.

##### Verify
- `pnpm app:compile`
- `pnpm app:lint`

##### Timeout
90000

#### Step 6.3: Update .env.example

Read `.env.example` and update it to include `NEXT_PUBLIC_CONVEX_URL`.

**Target content:**
```bash
GITHUB_API_KEY=""
CLAUDE_CODE_API_KEY=""
NEXT_PUBLIC_CONVEX_URL=""
```

Use the Edit tool.

##### Verify
- `pnpm app:compile`

##### Timeout
90000

### Phase 7: Final Verification

#### Step 7.1: Full build check

Run the full verification suite to confirm all acceptance criteria pass.

##### Verify
- `pnpm app:compile`
- `pnpm app:lint`

##### Timeout
120000

---

## 8. Post-Scaffold: Convex Deployment

After this spec executes, the user must run `npx convex dev` to:
1. Create/connect to a Convex project (interactive, requires `npx convex login` first)
2. Generate `convex/_generated/` types
3. Deploy schema and functions to Convex cloud
4. Set `NEXT_PUBLIC_CONVEX_URL` in `.env.local`

Server-side API keys (`GITHUB_API_KEY`, `CLAUDE_CODE_API_KEY`) must be set in the Convex dashboard under Environment Variables.

---

## 9. Change Log

| Version | Date | Changes |
|---------|------|---------|
| 1.0.0 | 2026-02-21 | Initial server scaffolding specification |
